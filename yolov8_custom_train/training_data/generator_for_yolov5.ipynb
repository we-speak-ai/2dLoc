{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed explanation:\n",
    "https://medium.com/@alexppppp/how-to-create-synthetic-dataset-for-computer-vision-object-detection-fd8ab2fa5249\n",
    "\n",
    "GitHub repo:\n",
    "https://github.com/alexppppp/synthetic-dataset-object-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Paths to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dict = {\n",
    "    1: {'folder': \"bw_code\", 'longest_min': 90, 'longest_max': 500},\n",
    "}\n",
    "\n",
    "PATH_MAIN = \"data/train\"\n",
    "\n",
    "for k, _ in obj_dict.items():\n",
    "    folder_name = obj_dict[k]['folder']\n",
    "    \n",
    "    files_imgs = sorted(os.listdir(os.path.join(PATH_MAIN, folder_name, 'images')))\n",
    "    files_imgs = sorted([os.path.join(PATH_MAIN, folder_name, 'images', f) for f in files_imgs])\n",
    "    \n",
    "    files_masks = sorted(os.listdir(os.path.join(PATH_MAIN, folder_name, 'masks')))\n",
    "    files_masks = sorted([os.path.join(PATH_MAIN, folder_name, 'masks', f) for f in files_masks])\n",
    "    \n",
    "    obj_dict[k]['images'] = files_imgs\n",
    "    obj_dict[k]['masks'] = files_masks\n",
    "    \n",
    "print(\"The first five files from the sorted list of battery images:\", obj_dict[1]['images'][:5])\n",
    "print(\"\\nThe first five files from the sorted list of battery masks:\", obj_dict[1]['masks'][:5])\n",
    "\n",
    "files_bg_imgs = os.listdir(os.path.join(PATH_MAIN, 'bg'))\n",
    "files_bg_imgs = [os.path.join(PATH_MAIN, 'bg', f) for f in files_bg_imgs]\n",
    "\n",
    "files_bg_noise_imgs = os.listdir(os.path.join(PATH_MAIN, \"bg_noise\", \"images\"))\n",
    "files_bg_noise_imgs = sorted([os.path.join(PATH_MAIN, \"bg_noise\", \"images\", f) for f in files_bg_noise_imgs])\n",
    "files_bg_noise_masks = os.listdir(os.path.join(PATH_MAIN, \"bg_noise\", \"masks\"))\n",
    "files_bg_noise_masks = sorted([os.path.join(PATH_MAIN, \"bg_noise\", \"masks\", f) for f in files_bg_noise_masks])\n",
    "\n",
    "print(\"\\nThe first five files from the sorted list of background images:\", files_bg_imgs[:5])\n",
    "print(\"\\nThe first five files from the sorted list of background noise images:\", files_bg_noise_imgs[:5])\n",
    "print(\"\\nThe first five files from the sorted list of background noise masks:\", files_bg_noise_masks[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(obj_dict[k]['images'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_and_mask(img_path, mask_path):\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mask = cv2.imread(mask_path)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mask_b = mask[:,:,0] == 0 # This is boolean mask\n",
    "    mask = mask_b.astype(np.uint8) # This is binary mask\n",
    "    \n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a random object and its binary mask\n",
    "\n",
    "img_path = obj_dict[1]['images'][0]\n",
    "mask_path = obj_dict[1]['masks'][0]\n",
    "\n",
    "img, mask = get_img_and_mask(img_path, mask_path)\n",
    "\n",
    "print(\"Image file:\", img_path)\n",
    "print(\"Mask file:\", mask_path)\n",
    "print(\"\\nShape of the image of the object:\", img.shape)\n",
    "print(\"Shape of the binary mask:\", mask.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('Object', fontsize=18)\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title('Binary mask', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Resizing background images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img, desired_max, desired_min=None):\n",
    "   \n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    longest, shortest = max(h, w), min(h, w)\n",
    "    longest_new = desired_max\n",
    "    if desired_min:\n",
    "        shortest_new = desired_min\n",
    "    else:\n",
    "        shortest_new = int(shortest * (longest_new / longest))\n",
    "    \n",
    "    if h > w:\n",
    "        h_new, w_new = longest_new, shortest_new\n",
    "    else:\n",
    "        h_new, w_new = shortest_new, longest_new\n",
    "        \n",
    "    transform_resize = A.Compose([\n",
    "        A.Sequential([\n",
    "        A.Resize(h_new, w_new, interpolation=1, always_apply=False, p=1)\n",
    "        ], p=1)\n",
    "    ])\n",
    "\n",
    "    transformed = transform_resize(image=img)\n",
    "    img_r = transformed[\"image\"]\n",
    "        \n",
    "    return img_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look how a random background image can be resized with resize_img() function\n",
    "\n",
    "img_bg_path = files_bg_imgs[5]\n",
    "img_bg = cv2.imread(img_bg_path)\n",
    "img_bg = cv2.cvtColor(img_bg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img_bg_resized_1 = resize_img(img_bg, desired_max=1920, desired_min=None)\n",
    "img_bg_resized_2 = resize_img(img_bg, desired_max=1920, desired_min=1080)\n",
    "\n",
    "print(\"Shape of the original background image:\", img_bg.shape)\n",
    "\n",
    "print(\"Shape of the resized background image (desired_max=1920, desired_min=None):\", img_bg_resized_1.shape)\n",
    "print(\"Shape of the resized background image (desired_max=1920, desired_min=1080):\", img_bg_resized_2.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "ax[0].imshow(img_bg_resized_1)\n",
    "ax[0].set_title('Resized (desired_max=1920, desired_min=None)', fontsize=18)\n",
    "ax[1].imshow(img_bg_resized_2)\n",
    "ax[1].set_title('Resized (desired_max=1920, desired_min=1080)', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Resizing and transforming objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_transform_obj(img, mask, longest_min, longest_max, transforms=False):\n",
    "   \n",
    "    h, w = mask.shape[0], mask.shape[1]\n",
    "    \n",
    "    longest, shortest = max(h, w), min(h, w)\n",
    "    longest_new = np.random.randint(longest_min, longest_max)\n",
    "    shortest_new = int(shortest * (longest_new / longest))\n",
    "    \n",
    "    if h > w:\n",
    "        h_new, w_new = longest_new, shortest_new\n",
    "    else:\n",
    "        h_new, w_new = shortest_new, longest_new\n",
    "        \n",
    "    transform_resize = A.Resize(h_new, w_new, interpolation=1, always_apply=False, p=1)\n",
    "\n",
    "    transformed_resized = transform_resize(image=img, mask=mask)\n",
    "    img_t = transformed_resized[\"image\"]\n",
    "    mask_t = transformed_resized[\"mask\"]\n",
    "        \n",
    "    if transforms:\n",
    "        transformed = transforms(image=img_t, mask=mask_t)\n",
    "        img_t = transformed[\"image\"]\n",
    "        mask_t = transformed[\"mask\"]\n",
    "        \n",
    "    return img_t, mask_t\n",
    "\n",
    "transforms_bg_obj = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.ColorJitter(brightness=0.3,\n",
    "                  contrast=0.3,\n",
    "                  saturation=0.3,\n",
    "                  hue=0.07,\n",
    "                  always_apply=False,\n",
    "                  p=1),\n",
    "    A.Blur(blur_limit=(3,15),\n",
    "           always_apply=False,\n",
    "           p=0.5)\n",
    "])\n",
    "\n",
    "transforms_obj = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.2),\n",
    "                               contrast_limit=0.1,\n",
    "                               brightness_by_max=True,\n",
    "                               always_apply=False,\n",
    "                               p=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look how image and binary mask of a random object can be transformed\n",
    "# with help of resize_transform_obj() function\n",
    "\n",
    "img_path = obj_dict[1]['images'][0]\n",
    "mask_path = obj_dict[1]['masks'][0]\n",
    "\n",
    "img, mask = get_img_and_mask(img_path, mask_path)\n",
    "\n",
    "img_t, mask_t = resize_transform_obj(img,\n",
    "                                     mask,\n",
    "                                     longest_min=30,  # It means that the longest side of the image will be not less than 150px, but not more than 800p\n",
    "                                     longest_max=400,\n",
    "                                     transforms=transforms_obj)\n",
    "\n",
    "print(\"Shape of the image of the transformed object:\", img_t.shape)\n",
    "print(\"Shape of the transformed binary mask:\", mask_t.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "ax[0].imshow(img_t)\n",
    "ax[0].set_title('Transformed object', fontsize=18)\n",
    "ax[1].imshow(mask_t)\n",
    "ax[1].set_title('Transformed binary mask', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Adding object to background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_obj(img_comp, mask_comp, img, mask, x, y, idx):\n",
    "    '''\n",
    "    img_comp - composition of objects\n",
    "    mask_comp - composition of objects` masks\n",
    "    img - image of object\n",
    "    mask - binary mask of object\n",
    "    x, y - coordinates where center of img is placed\n",
    "    Function returns img_comp in CV2 RGB format + mask_comp\n",
    "    '''\n",
    "    h_comp, w_comp = img_comp.shape[0], img_comp.shape[1]\n",
    "    \n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    x = x - int(w/2)\n",
    "    y = y - int(h/2)\n",
    "    \n",
    "    mask_b = mask == 1\n",
    "    mask_rgb_b = np.stack([mask_b, mask_b, mask_b], axis=2)\n",
    "    \n",
    "    if x >= 0 and y >= 0:\n",
    "    \n",
    "        h_part = h - max(0, y+h-h_comp) # h_part - part of the image which gets into the frame of img_comp along y-axis\n",
    "        w_part = w - max(0, x+w-w_comp) # w_part - part of the image which gets into the frame of img_comp along x-axis\n",
    "\n",
    "        img_comp[y:y+h_part, x:x+w_part, :] = img_comp[y:y+h_part, x:x+w_part, :] * ~mask_rgb_b[0:h_part, 0:w_part, :] + (img * mask_rgb_b)[0:h_part, 0:w_part, :]\n",
    "        mask_comp[y:y+h_part, x:x+w_part] = mask_comp[y:y+h_part, x:x+w_part] * ~mask_b[0:h_part, 0:w_part] + (idx * mask_b)[0:h_part, 0:w_part]\n",
    "        mask_added = mask[0:h_part, 0:w_part]\n",
    "        \n",
    "    elif x < 0 and y < 0:\n",
    "        \n",
    "        h_part = h + y\n",
    "        w_part = w + x\n",
    "        \n",
    "        img_comp[0:0+h_part, 0:0+w_part, :] = img_comp[0:0+h_part, 0:0+w_part, :] * ~mask_rgb_b[h-h_part:h, w-w_part:w, :] + (img * mask_rgb_b)[h-h_part:h, w-w_part:w, :]\n",
    "        mask_comp[0:0+h_part, 0:0+w_part] = mask_comp[0:0+h_part, 0:0+w_part] * ~mask_b[h-h_part:h, w-w_part:w] + (idx * mask_b)[h-h_part:h, w-w_part:w]\n",
    "        mask_added = mask[h-h_part:h, w-w_part:w]\n",
    "        \n",
    "    elif x < 0 and y >= 0:\n",
    "        \n",
    "        h_part = h - max(0, y+h-h_comp)\n",
    "        w_part = w + x\n",
    "        \n",
    "        img_comp[y:y+h_part, 0:0+w_part, :] = img_comp[y:y+h_part, 0:0+w_part, :] * ~mask_rgb_b[0:h_part, w-w_part:w, :] + (img * mask_rgb_b)[0:h_part, w-w_part:w, :]\n",
    "        mask_comp[y:y+h_part, 0:0+w_part] = mask_comp[y:y+h_part, 0:0+w_part] * ~mask_b[0:h_part, w-w_part:w] + (idx * mask_b)[0:h_part, w-w_part:w]\n",
    "        mask_added = mask[0:h_part, w-w_part:w]\n",
    "        \n",
    "    elif x >= 0 and y < 0:\n",
    "        \n",
    "        h_part = h + y\n",
    "        w_part = w - max(0, x+w-w_comp)\n",
    "        \n",
    "        img_comp[0:0+h_part, x:x+w_part, :] = img_comp[0:0+h_part, x:x+w_part, :] * ~mask_rgb_b[h-h_part:h, 0:w_part, :] + (img * mask_rgb_b)[h-h_part:h, 0:w_part, :]\n",
    "        mask_comp[0:0+h_part, x:x+w_part] = mask_comp[0:0+h_part, x:x+w_part] * ~mask_b[h-h_part:h, 0:w_part] + (idx * mask_b)[h-h_part:h, 0:w_part]\n",
    "        mask_added = mask[h-h_part:h, 0:w_part]\n",
    "    \n",
    "    return img_comp, mask_comp, mask_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bg_path = files_bg_imgs[26]\n",
    "img_bg = cv2.imread(img_bg_path)\n",
    "img_bg = cv2.cvtColor(img_bg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "h, w = img_bg.shape[0], img_bg.shape[1]\n",
    "mask_comp = np.zeros((h,w), dtype=np.uint8)\n",
    "\n",
    "img_path = obj_dict[1]['images'][0]\n",
    "mask_path = obj_dict[1]['masks'][0]\n",
    "img, mask = get_img_and_mask(img_path, mask_path)\n",
    "\n",
    "img_comp, mask_comp, _ = add_obj(img_bg, mask_comp, img, mask, x=800, y=600, idx=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "ax[0].imshow(img_comp)\n",
    "ax[0].set_title('Composition', fontsize=18)\n",
    "ax[1].imshow(mask_comp)\n",
    "ax[1].set_title('Composition mask', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_comp, mask_comp, _ = add_obj(img_comp, mask_comp, img, mask, x=1350, y=1050, idx=2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "ax[0].imshow(img_comp)\n",
    "ax[0].set_title('Composition', fontsize=18)\n",
    "ax[1].imshow(mask_comp)\n",
    "ax[1].set_title('Composition mask', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adding noise objects to background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bg_with_noise(files_bg_imgs,\n",
    "                         files_bg_noise_imgs,\n",
    "                         files_bg_noise_masks,\n",
    "                         bg_max=1920,\n",
    "                         bg_min=1080,\n",
    "                         max_objs_to_add=60,\n",
    "                         longest_bg_noise_max=1000,\n",
    "                         longest_bg_noise_min=200,\n",
    "                         blank_bg=False):\n",
    "    \n",
    "    if blank_bg:\n",
    "        img_comp_bg = np.ones((bg_min, bg_max,3), dtype=np.uint8) * 255\n",
    "        mask_comp_bg = np.zeros((bg_min, bg_max), dtype=np.uint8)\n",
    "    else:    \n",
    "        idx = np.random.randint(len(files_bg_imgs))\n",
    "        img_bg = cv2.imread(files_bg_imgs[idx])\n",
    "        img_bg = cv2.cvtColor(img_bg, cv2.COLOR_BGR2RGB)\n",
    "        img_comp_bg = resize_img(img_bg, bg_max, bg_min)\n",
    "        mask_comp_bg = np.zeros((img_comp_bg.shape[0], img_comp_bg.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    for i in range(1, np.random.randint(max_objs_to_add) + 2):\n",
    "\n",
    "        idx = np.random.randint(len(files_bg_noise_imgs))\n",
    "        img, mask = get_img_and_mask(files_bg_noise_imgs[idx], files_bg_noise_masks[idx])\n",
    "        x, y = np.random.randint(img_comp_bg.shape[1]), np.random.randint(img_comp_bg.shape[0])\n",
    "        img_t, mask_t = resize_transform_obj(img, mask, longest_bg_noise_min, longest_bg_noise_max, transforms=transforms_bg_obj)\n",
    "        img_comp_bg, _, _ = add_obj(img_comp_bg, mask_comp_bg, img_t, mask_t, x, y, i)\n",
    "        \n",
    "    return img_comp_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_comp_bg = create_bg_with_noise(files_bg_imgs,\n",
    "                                   files_bg_noise_imgs,\n",
    "                                   files_bg_noise_masks,\n",
    "                                   max_objs_to_add=20,\n",
    "                                   blank_bg=False)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(img_comp_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_comp_bg = create_bg_with_noise(files_bg_imgs,\n",
    "                                   files_bg_noise_imgs,\n",
    "                                   files_bg_noise_masks,\n",
    "                                   max_objs_to_add=20)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(img_comp_bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Controlling degree of overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_areas(mask_comp, obj_areas, overlap_degree=0.3):\n",
    "    obj_ids = np.unique(mask_comp).astype(np.uint8)[1:-1]\n",
    "    masks = mask_comp == obj_ids[:, None, None]\n",
    "    \n",
    "    ok = True\n",
    "    \n",
    "    if len(np.unique(mask_comp)) != np.max(mask_comp) + 1:\n",
    "        ok = False\n",
    "        return ok\n",
    "    \n",
    "    for idx, mask in enumerate(masks):\n",
    "        if np.count_nonzero(mask) / obj_areas[idx] < 1 - overlap_degree:\n",
    "            ok = False\n",
    "            break\n",
    "            \n",
    "    return ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Creating synthetic composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_composition(img_comp_bg,\n",
    "                       max_objs=15,\n",
    "                       overlap_degree=0.2,\n",
    "                       max_attempts_per_obj=10):\n",
    "\n",
    "    img_comp = img_comp_bg.copy()\n",
    "    h, w = img_comp.shape[0], img_comp.shape[1]\n",
    "    mask_comp = np.zeros((h,w), dtype=np.uint8)\n",
    "    \n",
    "    obj_areas = []\n",
    "    labels_comp = []\n",
    "    num_objs = np.random.randint(max_objs) + 2\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    for _ in range(1, num_objs):\n",
    "\n",
    "        obj_idx = np.random.randint(len(obj_dict)) + 1\n",
    "        \n",
    "        for _ in range(max_attempts_per_obj):\n",
    "\n",
    "            imgs_number = len(obj_dict[obj_idx]['images'])\n",
    "            idx = np.random.randint(imgs_number)\n",
    "            img_path = obj_dict[obj_idx]['images'][idx]\n",
    "            mask_path = obj_dict[obj_idx]['masks'][idx]\n",
    "            img, mask = get_img_and_mask(img_path, mask_path)\n",
    "\n",
    "            x, y = np.random.randint(w), np.random.randint(h)\n",
    "            longest_min = obj_dict[obj_idx]['longest_min']\n",
    "            longest_max = obj_dict[obj_idx]['longest_max']\n",
    "            img, mask = resize_transform_obj(img,\n",
    "                                             mask,\n",
    "                                             longest_min,\n",
    "                                             longest_max,\n",
    "                                             transforms=transforms_obj)\n",
    "\n",
    "            if i == 1:\n",
    "                img_comp, mask_comp, mask_added = add_obj(img_comp,\n",
    "                                                          mask_comp,\n",
    "                                                          img,\n",
    "                                                          mask,\n",
    "                                                          x,\n",
    "                                                          y,\n",
    "                                                          i)\n",
    "                obj_areas.append(np.count_nonzero(mask_added))\n",
    "                labels_comp.append(obj_idx)\n",
    "                i += 1\n",
    "                break\n",
    "            else:        \n",
    "                img_comp_prev, mask_comp_prev = img_comp.copy(), mask_comp.copy()\n",
    "                img_comp, mask_comp, mask_added = add_obj(img_comp,\n",
    "                                                          mask_comp,\n",
    "                                                          img,\n",
    "                                                          mask,\n",
    "                                                          x,\n",
    "                                                          y,\n",
    "                                                          i)\n",
    "                ok = check_areas(mask_comp, obj_areas, overlap_degree)\n",
    "                if ok:\n",
    "                    obj_areas.append(np.count_nonzero(mask_added))\n",
    "                    labels_comp.append(obj_idx)\n",
    "                    i += 1\n",
    "                    break\n",
    "                else:\n",
    "                    img_comp, mask_comp = img_comp_prev.copy(), mask_comp_prev.copy()        \n",
    "        \n",
    "    return img_comp, mask_comp, labels_comp, obj_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_comp, mask_comp, labels_comp, obj_areas = create_composition(img_comp_bg,\n",
    "                                                                 max_objs=15,\n",
    "                                                                 overlap_degree=0.2,\n",
    "                                                                 max_attempts_per_obj=10)\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.imshow(img_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "plt.imshow(mask_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels (classes of the objects) on the composition in order of object's addition:\", labels_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_ids = np.unique(mask_comp).astype(np.uint8)[1:]\n",
    "masks = mask_comp == obj_ids[:, None, None]\n",
    "\n",
    "print(\"Degree of how much area of each object is overlapped:\")\n",
    "\n",
    "for idx, mask in enumerate(masks):\n",
    "    print(np.count_nonzero(mask) / obj_areas[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {1: (255,0,0), 2: (0,255,0), 3: (0,0,255)}\n",
    "\n",
    "img_comp_bboxes = img_comp.copy()\n",
    "\n",
    "obj_ids = np.unique(mask_comp).astype(np.uint8)[1:]\n",
    "masks = mask_comp == obj_ids[:, None, None]\n",
    "\n",
    "for i in range(len(obj_ids)):\n",
    "    pos = np.where(masks[i])\n",
    "    xmin = np.min(pos[1])\n",
    "    xmax = np.max(pos[1])\n",
    "    ymin = np.min(pos[0])\n",
    "    ymax = np.max(pos[0])\n",
    "    img_comp_bboxes = cv2.rectangle(img_comp_bboxes,\n",
    "                                    (xmin, ymin),\n",
    "                                    (xmax,ymax),\n",
    "                                    colors[labels_comp[i]],\n",
    "                                    6)\n",
    "    \n",
    "plt.figure(figsize=(40,40))\n",
    "plt.imshow(img_comp_bboxes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Annotations in YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_annotations(mask_comp, labels_comp):\n",
    "    comp_w, comp_h = mask_comp.shape[1], mask_comp.shape[0]\n",
    "    \n",
    "    obj_ids = np.unique(mask_comp).astype(np.uint8)[1:]\n",
    "    masks = mask_comp == obj_ids[:, None, None]\n",
    "\n",
    "    annotations_yolo = []\n",
    "    for i in range(len(labels_comp)):\n",
    "        pos = np.where(masks[i])\n",
    "        xmin = np.min(pos[1])\n",
    "        xmax = np.max(pos[1])\n",
    "        ymin = np.min(pos[0])\n",
    "        ymax = np.max(pos[0])\n",
    "\n",
    "        xc = (xmin + xmax) / 2\n",
    "        yc = (ymin + ymax) / 2\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "\n",
    "        annotations_yolo.append([labels_comp[i] - 1,\n",
    "                                 round(xc/comp_w, 5),\n",
    "                                 round(yc/comp_h, 5),\n",
    "                                 round(w/comp_w, 5),\n",
    "                                 round(h/comp_h, 5)])\n",
    "\n",
    "    return annotations_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_yolo = create_yolo_annotations(mask_comp, labels_comp)\n",
    "for i in range(len(annotations_yolo)):\n",
    "    print(' '.join(str(el) for el in annotations_yolo[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Creating and saving synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(imgs_number, folder, split='train'):\n",
    "    time_start = time.time()\n",
    "    os.makedirs(os.path.join(folder, split, 'labels'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder, split, 'images'), exist_ok=True)\n",
    "    \n",
    "    for j in tqdm(range(imgs_number)):\n",
    "        img_comp_bg = create_bg_with_noise(files_bg_imgs,\n",
    "                                           files_bg_noise_imgs,\n",
    "                                           files_bg_noise_masks,\n",
    "                                           max_objs_to_add=60)\n",
    "        \n",
    "        img_comp, mask_comp, labels_comp, _ = create_composition(img_comp_bg,\n",
    "                                                                 max_objs=15,\n",
    "                                                                 overlap_degree=0.2,\n",
    "                                                                 max_attempts_per_obj=10)\n",
    "\n",
    "        img_comp = cv2.cvtColor(img_comp, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(os.path.join(folder, split, 'images/{}.jpg').format(j), img_comp)\n",
    "\n",
    "        try:\n",
    "            annotations_yolo = create_yolo_annotations(mask_comp, labels_comp)\n",
    "            for i in range(len(annotations_yolo)):\n",
    "                with open(os.path.join(folder, split, 'labels/{}.txt').format(j), \"a\") as f:\n",
    "                    f.write(' '.join(str(el) for el in annotations_yolo[i]) + '\\n')\n",
    "        except:\n",
    "            continue\n",
    "                \n",
    "    time_end = time.time()\n",
    "    time_total = round(time_end - time_start)\n",
    "    time_per_img = round((time_end - time_start) / imgs_number, 1)\n",
    "    \n",
    "    print(\"Generation of {} synthetic images is completed. It took {} seconds, or {} seconds per image\".format(imgs_number, time_total, time_per_img))\n",
    "    print(\"Images are stored in '{}'\".format(os.path.join(folder, split, 'images')))\n",
    "    print(\"Annotations are stored in '{}'\".format(os.path.join(folder, split, 'labels')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(10000, folder='dataset', split='train')\n",
    "#generate_dataset(200, folder='dataset', split='valid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
